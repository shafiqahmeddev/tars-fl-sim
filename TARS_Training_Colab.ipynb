{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tars-title"
   },
   "source": [
    "# TARS Federated Learning Training on Google Colab\n",
    "\n",
    "**TARS: Trust-Aware Reinforcement Selection for Robust Federated Learning**\n",
    "\n",
    "Author: Shafiq Ahmed (s.ahmed@essex.ac.uk)\n",
    "\n",
    "This notebook trains the TARS federated learning system to achieve 97%+ accuracy on MNIST and CIFAR-10 datasets.\n",
    "\n",
    "## Key Features:\n",
    "- Enhanced CNN architectures with batch normalization\n",
    "- Comprehensive data augmentation\n",
    "- TARS trust mechanism with Q-learning\n",
    "- Byzantine fault tolerance\n",
    "- Performance monitoring and early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"Using CPU - training will be slower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "# Clone the TARS repository\n",
    "!git clone https://github.com/shafiqahmeddev/tars-fl-sim.git\n",
    "%cd tars-fl-sim\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-requirements"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision numpy pandas matplotlib\n",
    "import sys\n",
    "sys.path.append('/content/tars-fl-sim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-section"
   },
   "source": [
    "## 2. Configuration and Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-modules"
   },
   "outputs": [],
   "source": [
    "# Import TARS modules\n",
    "from app.simulation import Simulation\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mnist-config"
   },
   "outputs": [],
   "source": [
    "# MNIST Configuration - Target: 97.7% accuracy\n",
    "mnist_config = {\n",
    "    \"dataset\": \"mnist\",\n",
    "    \"num_clients\": 10,\n",
    "    \"byzantine_pct\": 0.2,\n",
    "    \"attack_type\": \"sign_flipping\",\n",
    "    \"is_iid\": False,  # Non-IID for realistic federated learning\n",
    "    \"num_rounds\": 50,\n",
    "    \"local_epochs\": 3,\n",
    "    \n",
    "    # Client training parameters\n",
    "    \"client_lr\": 0.001,\n",
    "    \"client_optimizer\": \"adam\",\n",
    "    \"batch_size\": 32,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \n",
    "    # Q-learning parameters\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"discount_factor\": 0.9,\n",
    "    \"epsilon_start\": 1.0,\n",
    "    \"epsilon_decay\": 0.995,\n",
    "    \"epsilon_min\": 0.01,\n",
    "    \n",
    "    # Trust mechanism parameters\n",
    "    \"trust_beta\": 0.5,\n",
    "    \"trust_params\": {\n",
    "        \"w_sim\": 0.4,\n",
    "        \"w_loss\": 0.4,\n",
    "        \"w_norm\": 0.2,\n",
    "        \"norm_threshold\": 5.0\n",
    "    },\n",
    "    \n",
    "    # Training enhancements\n",
    "    \"use_scheduler\": True,\n",
    "    \"early_stopping\": True,\n",
    "    \"patience\": 10,\n",
    "    \"save_model\": True,\n",
    "    \"use_pretrained\": False,\n",
    "    \"force_retrain\": True\n",
    "}\n",
    "\n",
    "print(\"MNIST Configuration:\")\n",
    "for key, value in mnist_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cifar-config"
   },
   "outputs": [],
   "source": [
    "# CIFAR-10 Configuration - Target: 80.5%+ accuracy\n",
    "cifar_config = {\n",
    "    \"dataset\": \"cifar10\",\n",
    "    \"num_clients\": 10,\n",
    "    \"byzantine_pct\": 0.2,\n",
    "    \"attack_type\": \"sign_flipping\",\n",
    "    \"is_iid\": False,\n",
    "    \"num_rounds\": 50,\n",
    "    \"local_epochs\": 3,\n",
    "    \n",
    "    # Client training parameters (higher learning rate for CIFAR-10)\n",
    "    \"client_lr\": 0.001,\n",
    "    \"client_optimizer\": \"adam\",\n",
    "    \"batch_size\": 32,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \n",
    "    # Q-learning parameters\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"discount_factor\": 0.9,\n",
    "    \"epsilon_start\": 1.0,\n",
    "    \"epsilon_decay\": 0.995,\n",
    "    \"epsilon_min\": 0.01,\n",
    "    \n",
    "    # Trust mechanism parameters\n",
    "    \"trust_beta\": 0.5,\n",
    "    \"trust_params\": {\n",
    "        \"w_sim\": 0.4,\n",
    "        \"w_loss\": 0.4,\n",
    "        \"w_norm\": 0.2,\n",
    "        \"norm_threshold\": 5.0\n",
    "    },\n",
    "    \n",
    "    # Training enhancements\n",
    "    \"use_scheduler\": True,\n",
    "    \"early_stopping\": True,\n",
    "    \"patience\": 10,\n",
    "    \"save_model\": True,\n",
    "    \"use_pretrained\": False,\n",
    "    \"force_retrain\": True\n",
    "}\n",
    "\n",
    "print(\"CIFAR-10 Configuration:\")\n",
    "for key, value in cifar_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training-section"
   },
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-mnist"
   },
   "outputs": [],
   "source": [
    "# Train MNIST Model\n",
    "print(\"üöÄ Starting MNIST Training - Target: 97.7% accuracy\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "mnist_simulation = Simulation(mnist_config)\n",
    "mnist_history = mnist_simulation.run()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ MNIST Training Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-cifar"
   },
   "outputs": [],
   "source": [
    "# Train CIFAR-10 Model\n",
    "print(\"üöÄ Starting CIFAR-10 Training - Target: 80.5%+ accuracy\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cifar_simulation = Simulation(cifar_config)\n",
    "cifar_history = cifar_simulation.run()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ CIFAR-10 Training Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results-section"
   },
   "source": [
    "## 4. Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot-results"
   },
   "outputs": [],
   "source": [
    "# Plot training results\n",
    "def plot_training_results(history, dataset_name, target_accuracy):\n",
    "    if not history:\n",
    "        print(f\"No training history available for {dataset_name}\")\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(history)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'TARS Training Results - {dataset_name}', fontsize=16)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[0, 0].plot(df['round'], df['accuracy'], 'b-', linewidth=2, label='Accuracy')\n",
    "    axes[0, 0].axhline(y=target_accuracy, color='r', linestyle='--', label=f'Target ({target_accuracy}%)')\n",
    "    axes[0, 0].set_xlabel('Round')\n",
    "    axes[0, 0].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 0].set_title('Model Accuracy Over Time')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0, 1].plot(df['round'], df['loss'], 'r-', linewidth=2, label='Loss')\n",
    "    axes[0, 1].set_xlabel('Round')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].set_title('Training Loss Over Time')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Trust scores plot\n",
    "    axes[1, 0].plot(df['round'], df['avg_trust'], 'g-', linewidth=2, label='Average Trust')\n",
    "    axes[1, 0].set_xlabel('Round')\n",
    "    axes[1, 0].set_ylabel('Trust Score')\n",
    "    axes[1, 0].set_title('Average Trust Score Over Time')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Aggregation rules usage\n",
    "    rule_counts = df['chosen_rule'].value_counts()\n",
    "    axes[1, 1].pie(rule_counts.values, labels=rule_counts.index, autopct='%1.1f%%')\n",
    "    axes[1, 1].set_title('Aggregation Rules Usage')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    final_accuracy = df['accuracy'].iloc[-1]\n",
    "    max_accuracy = df['accuracy'].max()\n",
    "    avg_trust = df['avg_trust'].mean()\n",
    "    \n",
    "    print(f\"\\nüìä {dataset_name} Training Summary:\")\n",
    "    print(f\"  Final Accuracy: {final_accuracy:.2f}%\")\n",
    "    print(f\"  Best Accuracy: {max_accuracy:.2f}%\")\n",
    "    print(f\"  Average Trust: {avg_trust:.3f}\")\n",
    "    print(f\"  Total Rounds: {len(df)}\")\n",
    "    \n",
    "    if final_accuracy >= target_accuracy:\n",
    "        print(f\"  üéâ TARGET ACHIEVED! {final_accuracy:.2f}% >= {target_accuracy}%\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è  Target not reached: {final_accuracy:.2f}% < {target_accuracy}%\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Plot MNIST results\n",
    "print(\"MNIST Results:\")\n",
    "mnist_df = plot_training_results(mnist_history, \"MNIST\", 97.0)\n",
    "\n",
    "# Plot CIFAR-10 results\n",
    "print(\"\\nCIFAR-10 Results:\")\n",
    "cifar_df = plot_training_results(cifar_history, \"CIFAR-10\", 80.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save-results"
   },
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "if mnist_history:\n",
    "    mnist_df = pd.DataFrame(mnist_history)\n",
    "    mnist_df.to_csv(\"mnist_training_results.csv\", index=False)\n",
    "    print(\"üíæ MNIST results saved to mnist_training_results.csv\")\n",
    "\n",
    "if cifar_history:\n",
    "    cifar_df = pd.DataFrame(cifar_history)\n",
    "    cifar_df.to_csv(\"cifar10_training_results.csv\", index=False)\n",
    "    print(\"üíæ CIFAR-10 results saved to cifar10_training_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-section"
   },
   "source": [
    "## 5. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-files"
   },
   "outputs": [],
   "source": [
    "# Download trained models and results\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "# List available files\n",
    "print(\"Available files for download:\")\n",
    "for file in os.listdir('.'):\n",
    "    if file.endswith(('.csv', '.pth', '.pkl')):\n",
    "        print(f\"  üìÑ {file}\")\n",
    "\n",
    "# Download checkpoints if they exist\n",
    "if os.path.exists('checkpoints'):\n",
    "    print(\"\\nCheckpoint files:\")\n",
    "    for file in os.listdir('checkpoints'):\n",
    "        print(f\"  üîÑ checkpoints/{file}\")\n",
    "\n",
    "# Uncomment to download specific files\n",
    "# files.download('mnist_training_results.csv')\n",
    "# files.download('cifar10_training_results.csv')\n",
    "# files.download('checkpoints/mnist_global_model.pth')\n",
    "# files.download('checkpoints/cifar10_global_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next-steps"
   },
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "üéØ **Performance Targets:**\n",
    "- MNIST: 97.7% accuracy\n",
    "- CIFAR-10: 80.5% accuracy\n",
    "\n",
    "üîß **If targets not met, try:**\n",
    "- Increase number of rounds\n",
    "- Adjust learning rates\n",
    "- Modify trust mechanism parameters\n",
    "- Experiment with different optimizers\n",
    "\n",
    "üìä **Model Analysis:**\n",
    "- Check convergence patterns\n",
    "- Analyze trust scores\n",
    "- Review aggregation rule selection\n",
    "- Examine Byzantine attack impact\n",
    "\n",
    "üíæ **Model Deployment:**\n",
    "- Download trained models\n",
    "- Use checkpoints for inference\n",
    "- Deploy TARS agent for production"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}